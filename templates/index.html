<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sign Language Detection</title>
</head>
<body>
    <h1>Sign Language Detection</h1>
    <video id="video" autoplay></video>
    <canvas id="canvas" style="display: none;"></canvas>
    <p id="prediction">Prediction: </p>
    <button id="start">Start Detection</button>

    <script>
        let isRunning = false;

        async function startVideo() {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
        }

        async function captureFrameAndSend() {
            if (!isRunning) return;
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const context = canvas.getContext('2d');

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            context.drawImage(video, 0, 0, canvas.width, canvas.height);

            canvas.toBlob(async (blob) => {
                const formData = new FormData();
                formData.append('video_frame', blob, 'frame.jpg');

                const response = await fetch('/predict_gesture', {
                    method: 'POST',
                    body: formData
                });
                const result = await response.json();
                document.getElementById('prediction').innerText = 'Prediction: ' + (result.prediction || result.error);
            }, 'image/jpeg');

            setTimeout(captureFrameAndSend, 1000); // Capture every second
        }

        document.getElementById('start').addEventListener('click', () => {
            isRunning = !isRunning;
            if (isRunning) {
                captureFrameAndSend();
            }
        });

        window.onload = startVideo;
    </script>
</body>
</html>
